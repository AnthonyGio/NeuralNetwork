import numpy as np

# Default activation function


def sigmoid(z, derivative=False):
    if derivative:
        return z * (1.0 - z)
    else:
        return 1.0 / (1.0 + np.exp(-z))

# Alternative activation function


def tanh(z, derivative=False):
    if derivative:
        return 1 - y * y
    else:
        return (2 * sigmoid(2 * z)) - 1

# Returns list as a vector (n x 1 matrix)


def vectorize(list):
    return np.matrix([list]).transpose()


'''
Neural network object

:param int input: Number of inputs for the network
:param int hidden: Number of nodes in each hidden layer
:param int layers: Number of hidden layers in the network
:param int output: Number of possible classifications (Length of output vector)
:param boolean preload_params: Load parameters from "params.txt". File will be auto generated by calling write_params()
:param function activation: Activation function to use for calculating node activation values
:param float epsilon: Difference to use when estimating gradients for debugging
:param float regularization_coefficient: Value with which all regularization terms will be multiplied by
:param float learning_rate: Coefficient to scale each step in gradient descent (Too big won't converge, too small will be slow; .1 to 1 is a safe bet)
:param boolean debug: Enable some features to make the network easier to trace
:raises IOError: If preload_params is True but no params.npy is found
:raises RuntimeError: If preload_params is True but the params.npy file has an incorrect or incoherent number of values
'''


class Neural_Network(object):
    def __init__(self, input, hidden, layers, output, preload_params=False, debug=False, activation=sigmoid,
                 epsilon=.0001, regularization_coefficient=.1, learning_rate=.1):

        # Append bias node to input
        self.input = input + 1
        self.hidden = hidden
        self.layers = layers
        self.output = output
        self.preload_params = preload_params
        self.debug = debug
        self.activation_function = activation
        self.epsilon = epsilon
        self.regularization_coefficient = regularization_coefficient
        self.learning_rate = learning_rate

        ### Activation vectors ###
        self.activation = []

        # Input layer
        self.activation.append(np.ones((self.input, 1)))

        # Hidden layers
        for i in range(self.layers):
            self.activation.append(np.zeros((self.hidden, 1)))

        # Output layer
        self.activation.append(np.zeros((self.output, 1)))

        ### Theta matrices ###
        self.theta = []

        # Load parameters
        if self.preload_params:
            try:
                self.read_params()
            except IOError:
                raise IOError(
                    'No params.npy found, run with preload_params=False to generate random parameters')
        else:
            # Randomly generate parameters
            # Size of theta matrix for layer j = (Size of activation vector (j+1)) x (Size of activation vector j)

            # Weights between input layer and first hidden layer
            # If zero hidden layers, connect directly to output layer
            if self.layers > 0:
                self.theta.append(np.random.rand(self.hidden, self.input))
            else:
                self.theta.append(np.random.rand(self.output, self.input))

            # Weights between hidden layers
            for i in range(self.layers - 1):
                self.theta.append(np.random.rand(self.hidden, self.hidden))

            # Weights between final hidden layer and output
            self.theta.append(np.random.rand(self.output, self.hidden))

            # Set random interval to [-1,1]
            for i in range(self.theta.__len__()):
                self.theta[i] *= 2
                self.theta[i] -= 1

        # List to hold delta vectors for each layer
        self.delta = [0] * (self.layers + 2)

    # Write parameters to file
    def write_params(self):
        file = open('params.npy', 'wb')
        np.save(file, self.theta)
        file.close()

    # Load parameters from file
    def read_params(self):
        file = open('params.npy', 'rb')
        self.theta = np.load(file)
        file.close()

    # Feed single input through network, returns hypothesis
    # Hypothesis is a vector of confidence values for each classification
    def forward_propagate(self, input):
        # Check for proper number of inputs
        if input.__len__() != self.input - 1:
            raise ValueError("Wrong number of inputs for this network")
        # Map input to activation vector 0 (Skipping bias node)
        else:
            for i in range(input.__len__()):
                self.activation[0][i + 1][0] = float(input[i])

        # Compute activations for each layer after input
        for i in range(self.activation.__len__() - 1):
            tmp = np.dot(self.theta[i], self.activation[i])
            tmp = self.activation_function(tmp)
            self.activation[i + 1] = tmp

        # Return hypothesis (Activation of output layer)
        return self.activation[-1]

    # Feeds list of inputs through network, returns list of hypotheses
    def batch_feed(self, input):
        hypotheses = []
        for i in range(input.__len__()):
            hypotheses.append(self.forward_propagate(input[i]))
        return hypotheses

    # Calculates delta terms for a single training example. Should be executed immediately after forward prop of training input
    def back_propagate(self, label):

        # Compute delta for output layer as (Training label vector - hypothesized vector)
        self.delta[-1] = np.subtract(self.activation[-1], vectorize(label))

        # Calculate deltas for hidden layers
        for i in range(self.activation.__len__() - 2, 0, -1):
            term1 = np.dot(self.theta[i].transpose(), self.delta[i + 1])
            term2 = self.activation_function(
                self.activation[i], derivative=True)
            self.delta[i] = np.multiply(term1, term2)

        return self.delta

    # Train network on labelled data
    def train(self, training, labels):
        m = training.__len__()

        # TODO proper convergence test
        # A flat number of iterations is convenient for testing, when convergence may take a long time

        # For each training example:
        # Forward prop to compute hypothesis
        # Back prop to compute error values for each node
        # Regularize, then sum up and average into list of partial derivative matrices for theta values
        # Perform gradient descent step
        for iteration in range(100):
            delta_sum = [0] * self.theta.__len__()
            for i in range(m):
                self.forward_propagate(training[i])
                self.back_propagate(labels[i])
                for j in range(delta_sum.__len__()):
                    delta_sum[j] += np.dot(self.delta[j + 1],
                                           self.activation[j].transpose())

            for i in range(delta_sum.__len__()):
                delta_sum[i] *= (1.0 / m)
                delta_sum[i] += (self.regularization_coefficient *
                                 self.theta[i])
            self.gradient_descent(delta_sum)
            if self.debug and (iteration == iteration):
                print '---Cost for iteration '+str(iteration)+'---'
                print self.cost(self.batch_feed(training), labels)

    # Computes cost of the current parameters on given training data as a function of avg difference between hypothesis and label
    def cost(self, hypotheses, labels):
        sum1 = 0
        # For each training example
        for i in range(hypotheses.__len__()):
            sum2 = 0
            # For each possible classification, accumulate the sum of the differences between hypothesis and label
            for k in range(labels[0].__len__()):
                sum2 += labels[i][k] * np.log(hypotheses[i][k]) + (
                    1.0 - labels[i][k]) * np.log(1.0 - hypotheses[i][k])
            sum1 += sum2
        sum1 = sum1 * (-1 / hypotheses.__len__())

        # Compute regularization term to add
        regularization = 0
        for i in range(self.theta.__len__()):
            for j in range(np.shape(self.theta[i])[0]):
                for k in range(np.shape(self.theta[i])[1]):
                    regularization += self.theta[i][j, k] ** 2
        regularization = (
            regularization * self.regularization_coefficient) / (2 * hypotheses.__len__())
        return sum1 + regularization

    # Estimates partial derivatives (VERY slow, do not use for training)
    def gradient_checking(self, train, labels):
        gradients = self.theta[:]
        backup_theta = self.theta[:]
        for i in range(self.theta.__len__()):
            for j in range(np.shape(self.theta[i])[0]):
                for k in range(np.shape(self.theta[i])[1]):
                    self.theta[i][j, k] += self.epsilon
                    term1 = self.cost(self.batch_feed(train), labels)
                    self.theta[i][j, k] -= (2 * self.epsilon)
                    term2 = self.cost(self.batch_feed(train), labels)
                    gradients[i][j, k] = (term1 - term2) / (2 * self.epsilon)
                    self.theta = backup_theta[:]
        return gradients

    # Test network on labelled data, returns percentage of correctly predicted data
    def test(self, train, labels):
        hypotheses = self.batch_feed(train)
        correct = 0
        m = hypotheses.__len__()
        for i in range(m):
            hypotheses[i] = np.asarray(hypotheses[i])
            labels[i] = np.asarray(labels[i])
            if np.argmax(labels[i]) == np.argmax(hypotheses[i]):
                correct += 1
        accuracy = float(correct)/float(m)
        return 'Accuracy: '+str(accuracy)

    # Calculate new parameters as product of learning rate and partial derivative for each parameter
    def gradient_descent(self, derivatives):
        for i in range(self.theta.__len__()):
            for j in range(np.shape(self.theta[i])[0]):
                for k in range(np.shape(self.theta[i])[1]):
                    self.theta[i][j,
                                  k] -= (self.learning_rate * derivatives[i][j, k])
        return
